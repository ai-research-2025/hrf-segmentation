{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# HRF Segmentation U-Net Model Evaluation\n",
                "\n",
                "This notebook evaluates the trained U-Net and Attention U-Net models on HRF (Hyperreflective Foci) segmentation in retinal OCT images.\n",
                "\n",
                "**Dataset**: 435 OCT images with expert-annotated HRF masks\n",
                "\n",
                "**Models**: U-Net and Attention U-Net (PyTorch)\n",
                "\n",
                "**Authors**: Pavithra Kodiyalbail Chakrapani, Preetham Kumar, Sulatha V Bhandary, Geetha Maiya, Shailaja S, Steven Fernandes, Prakhar Choudhary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup"
            },
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install torch torchvision tqdm scikit-learn matplotlib seaborn opencv-python-headless pillow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "imports"
            },
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import cv2\n",
                "from glob import glob\n",
                "from tqdm import tqdm\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from sklearn.metrics import (\n",
                "    confusion_matrix, accuracy_score, precision_score, recall_score,\n",
                "    f1_score, jaccard_score, roc_curve, auc, roc_auc_score\n",
                ")\n",
                "from PIL import Image\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mount"
            },
            "source": [
                "## 2. Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "mount_drive"
            },
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config"
            },
            "source": [
                "## 3. Configuration\n",
                "\n",
                "**Update these paths according to your Google Drive structure**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "config_paths"
            },
            "outputs": [],
            "source": [
                "# IMPORTANT: Update these paths to match your Google Drive structure\n",
                "BASE_DIR = '/content/drive/MyDrive/HRF-DATASET'\n",
                "IMAGES_DIR = os.path.join(BASE_DIR, 'HRF_IMAGES')\n",
                "MASKS_DIR = os.path.join(BASE_DIR, 'HRF_MASKS')\n",
                "UNET_MODEL_PATH = os.path.join(BASE_DIR, 'unet_best_model.pth')\n",
                "AUNET_MODEL_PATH = os.path.join(BASE_DIR, 'aunet_best_model.pth')\n",
                "\n",
                "# Output directory for results\n",
                "OUTPUT_DIR = '/content/evaluation_results'\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Device configuration\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "model_def"
            },
            "source": [
                "## 4. Model Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "unet_modules"
            },
            "outputs": [],
            "source": [
                "# U-Net Building Blocks\n",
                "class DoubleConv(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
                "        super().__init__()\n",
                "        if not mid_channels:\n",
                "            mid_channels = out_channels\n",
                "        self.double_conv = nn.Sequential(\n",
                "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
                "            nn.BatchNorm2d(mid_channels),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
                "            nn.BatchNorm2d(out_channels),\n",
                "            nn.ReLU(inplace=True)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.double_conv(x)\n",
                "\n",
                "class Down(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels):\n",
                "        super().__init__()\n",
                "        self.maxpool_conv = nn.Sequential(\n",
                "            nn.MaxPool2d(2),\n",
                "            DoubleConv(in_channels, out_channels)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.maxpool_conv(x)\n",
                "\n",
                "class Up(nn.Module):\n",
                "    def __init__(self, in_channels_deeper, in_channels_skip, out_channels, bilinear=False):\n",
                "        super().__init__()\n",
                "        if bilinear:\n",
                "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
                "            self.conv = DoubleConv(in_channels_skip + in_channels_deeper, out_channels)\n",
                "        else:\n",
                "            self.up = nn.ConvTranspose2d(in_channels_deeper, in_channels_deeper // 2, kernel_size=2, stride=2)\n",
                "            self.conv = DoubleConv(in_channels_skip + in_channels_deeper // 2, out_channels)\n",
                "\n",
                "    def forward(self, x_deeper, x_skip):\n",
                "        x_deeper = self.up(x_deeper)\n",
                "        diffY = x_skip.size()[2] - x_deeper.size()[2]\n",
                "        diffX = x_skip.size()[3] - x_deeper.size()[3]\n",
                "        x_deeper = F.pad(x_deeper, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
                "        x = torch.cat([x_skip, x_deeper], dim=1)\n",
                "        return self.conv(x)\n",
                "\n",
                "class OutConv(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels):\n",
                "        super().__init__()\n",
                "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.conv(x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "unet_model"
            },
            "outputs": [],
            "source": [
                "# U-Net Model\n",
                "class UNet(nn.Module):\n",
                "    def __init__(self, n_channels=3, n_classes=1, bilinear=False, base_filters=64):\n",
                "        super().__init__()\n",
                "        self.n_channels = n_channels\n",
                "        self.n_classes = n_classes\n",
                "        self.bilinear = bilinear\n",
                "        self.base_filters = base_filters\n",
                "\n",
                "        self.inc = DoubleConv(n_channels, base_filters)\n",
                "        self.down1 = Down(base_filters, base_filters * 2)\n",
                "        self.down2 = Down(base_filters * 2, base_filters * 4)\n",
                "        self.down3 = Down(base_filters * 4, base_filters * 8)\n",
                "        self.down4 = Down(base_filters * 8, base_filters * 16)\n",
                "\n",
                "        self.up4 = Up(base_filters * 16, base_filters * 8, base_filters * 8, bilinear)\n",
                "        self.up3 = Up(base_filters * 8, base_filters * 4, base_filters * 4, bilinear)\n",
                "        self.up2 = Up(base_filters * 4, base_filters * 2, base_filters * 2, bilinear)\n",
                "        self.up1 = Up(base_filters * 2, base_filters, base_filters, bilinear)\n",
                "        \n",
                "        self.outc = OutConv(base_filters, n_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x1 = self.inc(x)\n",
                "        x2 = self.down1(x1)\n",
                "        x3 = self.down2(x2)\n",
                "        x4 = self.down3(x3)\n",
                "        x5 = self.down4(x4)\n",
                "\n",
                "        x = self.up4(x5, x4)\n",
                "        x = self.up3(x, x3)\n",
                "        x = self.up2(x, x2)\n",
                "        x = self.up1(x, x1)\n",
                "        \n",
                "        logits = self.outc(x)\n",
                "        return logits"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "attention_blocks"
            },
            "outputs": [],
            "source": [
                "# Attention U-Net Components\n",
                "class AttentionBlock(nn.Module):\n",
                "    def __init__(self, F_g, F_l, F_int):\n",
                "        super().__init__()\n",
                "        self.W_g = nn.Sequential(\n",
                "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
                "            nn.BatchNorm2d(F_int)\n",
                "        )\n",
                "        self.W_x = nn.Sequential(\n",
                "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
                "            nn.BatchNorm2d(F_int)\n",
                "        )\n",
                "        self.psi = nn.Sequential(\n",
                "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
                "            nn.BatchNorm2d(1),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "        self.relu = nn.ReLU(inplace=True)\n",
                "        \n",
                "    def forward(self, g, x):\n",
                "        g1 = self.W_g(g)\n",
                "        x1 = self.W_x(x)\n",
                "        if g1.size()[2:] != x1.size()[2:]:\n",
                "            g1 = F.interpolate(g1, size=x1.size()[2:], mode='bilinear', align_corners=True)\n",
                "        psi = self.relu(g1 + x1)\n",
                "        psi = self.psi(psi)\n",
                "        return x * psi\n",
                "\n",
                "class UpAttention(nn.Module):\n",
                "    def __init__(self, in_channels_deeper, in_channels_skip, out_channels, bilinear=False):\n",
                "        super().__init__()\n",
                "        self.attention = AttentionBlock(F_g=in_channels_deeper, F_l=in_channels_skip, F_int=in_channels_skip // 2)\n",
                "        if bilinear:\n",
                "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
                "            self.conv = DoubleConv(in_channels_skip + in_channels_deeper, out_channels)\n",
                "        else:\n",
                "            self.up = nn.ConvTranspose2d(in_channels_deeper, in_channels_deeper // 2, kernel_size=2, stride=2)\n",
                "            self.conv = DoubleConv(in_channels_skip + in_channels_deeper // 2, out_channels)\n",
                "            \n",
                "    def forward(self, x_deeper, x_skip):\n",
                "        x_upsampled = self.up(x_deeper)\n",
                "        diffY = x_skip.size()[2] - x_upsampled.size()[2]\n",
                "        diffX = x_skip.size()[3] - x_upsampled.size()[3]\n",
                "        x_upsampled = F.pad(x_upsampled, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
                "        x_skip_attended = self.attention(g=x_deeper, x=x_skip)\n",
                "        x = torch.cat([x_skip_attended, x_upsampled], dim=1)\n",
                "        return self.conv(x)\n",
                "\n",
                "class AttentionUNet(nn.Module):\n",
                "    def __init__(self, n_channels=3, n_classes=1, bilinear=False, base_filters=64):\n",
                "        super().__init__()\n",
                "        self.n_channels = n_channels\n",
                "        self.n_classes = n_classes\n",
                "        self.bilinear = bilinear\n",
                "        self.base_filters = base_filters\n",
                "\n",
                "        self.inc = DoubleConv(n_channels, base_filters)\n",
                "        self.down1 = Down(base_filters, base_filters * 2)\n",
                "        self.down2 = Down(base_filters * 2, base_filters * 4)\n",
                "        self.down3 = Down(base_filters * 4, base_filters * 8)\n",
                "        self.down4 = Down(base_filters * 8, base_filters * 16)\n",
                "\n",
                "        self.up4 = UpAttention(base_filters * 16, base_filters * 8, base_filters * 8, bilinear)\n",
                "        self.up3 = UpAttention(base_filters * 8, base_filters * 4, base_filters * 4, bilinear)\n",
                "        self.up2 = UpAttention(base_filters * 4, base_filters * 2, base_filters * 2, bilinear)\n",
                "        self.up1 = UpAttention(base_filters * 2, base_filters, base_filters, bilinear)\n",
                "        \n",
                "        self.outc = OutConv(base_filters, n_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x1 = self.inc(x)\n",
                "        x2 = self.down1(x1)\n",
                "        x3 = self.down2(x2)\n",
                "        x4 = self.down3(x3)\n",
                "        x5 = self.down4(x4)\n",
                "\n",
                "        x = self.up4(x5, x4)\n",
                "        x = self.up3(x, x3)\n",
                "        x = self.up2(x, x2)\n",
                "        x = self.up1(x, x1)\n",
                "        \n",
                "        logits = self.outc(x)\n",
                "        return logits"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "load_models"
            },
            "source": [
                "## 5. Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_model_func"
            },
            "outputs": [],
            "source": [
                "def load_model(model_type, checkpoint_path, device):\n",
                "    \"\"\"Load a trained model from checkpoint\"\"\"\n",
                "    if model_type == 'unet':\n",
                "        model = UNet(n_channels=3, n_classes=1, bilinear=False, base_filters=64)\n",
                "    elif model_type == 'attention_unet':\n",
                "        model = AttentionUNet(n_channels=3, n_classes=1, bilinear=False, base_filters=64)\n",
                "    else:\n",
                "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
                "    \n",
                "    print(f\"Loading {model_type} from {checkpoint_path}...\")\n",
                "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
                "    model.load_state_dict(checkpoint['model_state_dict'])\n",
                "    model.to(device)\n",
                "    model.eval()\n",
                "    print(f\"{model_type} loaded successfully!\")\n",
                "    \n",
                "    return model\n",
                "\n",
                "# Load both models\n",
                "print(\"=\"*60)\n",
                "unet = load_model('unet', UNET_MODEL_PATH, DEVICE)\n",
                "print(\"=\"*60)\n",
                "aunet = load_model('attention_unet', AUNET_MODEL_PATH, DEVICE)\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "data_loading"
            },
            "source": [
                "## 6. Data Loading Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "data_load_func"
            },
            "outputs": [],
            "source": [
                "def load_image(image_path):\n",
                "    \"\"\"Load and preprocess an image\"\"\"\n",
                "    img = cv2.imread(image_path)\n",
                "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    return img\n",
                "\n",
                "def load_mask(mask_path):\n",
                "    \"\"\"Load and preprocess a mask\"\"\"\n",
                "    from PIL import Image\n",
                "    # Load .ome.tiff mask\n",
                "    mask = Image.open(mask_path)\n",
                "    mask = np.array(mask)\n",
                "    if len(mask.shape) == 3:\n",
                "        mask = mask[:, :, 0]  # Take first channel if RGB\n",
                "    return mask\n",
                "\n",
                "def apply_clahe(image: np.ndarray) -> np.ndarray:\n",
                "    \"\"\"Apply CLAHE preprocessing (for Attention U-Net)\"\"\"\n",
                "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
                "    l, a, b = cv2.split(lab)\n",
                "    \n",
                "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
                "    cl = clahe.apply(l)\n",
                "    \n",
                "    limg = cv2.merge((cl, a, b))\n",
                "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
                "    return final\n",
                "\n",
                "def preprocess_for_model(image, mask, use_clahe=False):\n",
                "    \"\"\"\n",
                "    Convert image and mask to tensors\n",
                "    \n",
                "    Args:\n",
                "        image: Input image (RGB numpy array)\n",
                "        mask: Ground truth mask\n",
                "        use_clahe: If True, apply CLAHE + Z-score normalization (for Attention U-Net)\n",
                "                  If False, apply simple 0-255 normalization (for U-Net)\n",
                "    \"\"\"\n",
                "    # Apply CLAHE for Attention U-Net\n",
                "    if use_clahe:\n",
                "        image = apply_clahe(image)\n",
                "    \n",
                "    # Normalize to [0, 1]\n",
                "    image = image.astype(np.float32) / 255.0\n",
                "    \n",
                "    # Apply Z-Score normalization for Attention U-Net (ImageNet stats)\n",
                "    if use_clahe:\n",
                "        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
                "        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
                "        image = (image - mean) / std\n",
                "    \n",
                "    # Create tensor and ensure float32\n",
                "    image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()\n",
                "    \n",
                "    # Normalize mask to binary\n",
                "    mask_tensor = torch.from_numpy(mask).float()\n",
                "    mask_tensor = (mask_tensor > 0).float()  # Binary mask\n",
                "    \n",
                "    return image_tensor, mask_tensor\n",
                "\n",
                "# Get all image and mask paths\n",
                "image_paths = sorted(glob(os.path.join(IMAGES_DIR, '*.jpeg')))\n",
                "mask_paths = []\n",
                "for img_path in image_paths:\n",
                "    img_name = os.path.splitext(os.path.basename(img_path))[0]\n",
                "    mask_path = os.path.join(MASKS_DIR, f\"{img_name}_HRF.ome.tiff\")\n",
                "    if os.path.exists(mask_path):\n",
                "        mask_paths.append(mask_path)\n",
                "    else:\n",
                "        print(f\"Warning: Mask not found for {img_name}\")\n",
                "\n",
                "print(f\"Found {len(image_paths)} images\")\n",
                "print(f\"Found {len(mask_paths)} masks\")\n",
                "\n",
                "# Use 15% as test set (matching the training split)\n",
                "test_split = int(0.15 * len(image_paths))\n",
                "test_image_paths = image_paths[-test_split:]\n",
                "test_mask_paths = mask_paths[-test_split:]\n",
                "\n",
                "print(f\"\\nUsing {len(test_image_paths)} images for testing\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "inference"
            },
            "source": [
                "## 7. Run Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_inference"
            },
            "outputs": [],
            "source": [
                "def run_inference(model, image_tensor, device):\n",
                "    \"\"\"Run inference on a single image\"\"\"\n",
                "    with torch.no_grad():\n",
                "        image_tensor = image_tensor.to(device)\n",
                "        output = model(image_tensor)\n",
                "        prob = torch.sigmoid(output).cpu().squeeze().numpy()\n",
                "    return prob\n",
                "\n",
                "# Store predictions and ground truth\n",
                "unet_predictions = []\n",
                "aunet_predictions = []\n",
                "ground_truth = []\n",
                "test_images = []\n",
                "\n",
                "print(\"Running inference on test set...\")\n",
                "for img_path, mask_path in tqdm(zip(test_image_paths, test_mask_paths), total=len(test_image_paths)):\n",
                "    # Load data\n",
                "    image = load_image(img_path)\n",
                "    mask = load_mask(mask_path)\n",
                "    \n",
                "    # Preprocess\n",
                "    image_tensor, mask_tensor = preprocess_for_model(image, mask)\n",
                "    \n",
                "    # Run inference\n",
                "    unet_pred = run_inference(unet, image_tensor, DEVICE)\n",
                "    aunet_pred = run_inference(aunet, image_tensor, DEVICE)\n",
                "    \n",
                "    # Store results\n",
                "    unet_predictions.append(unet_pred)\n",
                "    aunet_predictions.append(aunet_pred)\n",
                "    ground_truth.append(mask_tensor.numpy())\n",
                "    test_images.append(image)\n",
                "\n",
                "print(\"\\nInference completed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "metrics"
            },
            "source": [
                "## 8. Calculate Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "calc_metrics"
            },
            "outputs": [],
            "source": [
                "def calculate_metrics(y_true_list, y_pred_list, threshold=0.5):\n",
                "    \"\"\"Calculate segmentation metrics\"\"\"\n",
                "    # Flatten all predictions and ground truth\n",
                "    y_true_flat = np.concatenate([y.flatten() for y in y_true_list])\n",
                "    y_pred_flat = np.concatenate([y.flatten() for y in y_pred_list])\n",
                "    y_pred_binary_flat = (y_pred_flat > threshold).astype(np.float32)\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy = accuracy_score(y_true_flat, y_pred_binary_flat)\n",
                "    precision = precision_score(y_true_flat, y_pred_binary_flat, zero_division=0)\n",
                "    recall = recall_score(y_true_flat, y_pred_binary_flat, zero_division=0)\n",
                "    f1 = f1_score(y_true_flat, y_pred_binary_flat, zero_division=0)\n",
                "    iou = jaccard_score(y_true_flat, y_pred_binary_flat, zero_division=0)\n",
                "    \n",
                "    # Dice coefficient\n",
                "    dice = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
                "    \n",
                "    # Specificity\n",
                "    cm = confusion_matrix(y_true_flat, y_pred_binary_flat)\n",
                "    tn, fp, fn, tp = cm.ravel()\n",
                "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
                "    \n",
                "    # AUC-ROC\n",
                "    try:\n",
                "        auc_score = roc_auc_score(y_true_flat, y_pred_flat)\n",
                "    except:\n",
                "        auc_score = 0.0\n",
                "    \n",
                "    metrics = {\n",
                "        'Dice': dice,\n",
                "        'IoU': iou,\n",
                "        'Precision': precision,\n",
                "        'Recall': recall,\n",
                "        'F1': f1,\n",
                "        'Specificity': specificity,\n",
                "        'Jaccard': iou,\n",
                "        'AUC': auc_score,\n",
                "        'TP': int(tp),\n",
                "        'TN': int(tn),\n",
                "        'FP': int(fp),\n",
                "        'FN': int(fn)\n",
                "    }\n",
                "    \n",
                "    return metrics, cm\n",
                "\n",
                "# Calculate metrics for both models\n",
                "print(\"Calculating metrics for U-Net...\")\n",
                "unet_metrics, unet_cm = calculate_metrics(ground_truth, unet_predictions)\n",
                "\n",
                "print(\"Calculating metrics for Attention U-Net...\")\n",
                "aunet_metrics, aunet_cm = calculate_metrics(ground_truth, aunet_predictions)\n",
                "\n",
                "# Display results\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"EVALUATION RESULTS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"{'Metric':<20} {'U-Net':<20} {'Attention U-Net':<20}\")\n",
                "print(\"-\"*70)\n",
                "for key in ['Dice', 'IoU', 'Precision', 'Recall', 'F1', 'Specificity', 'AUC']:\n",
                "    print(f\"{key:<20} {unet_metrics[key]:<20.4f} {aunet_metrics[key]:<20.4f}\")\n",
                "print(\"-\"*70)\n",
                "print(f\"\\nU-Net Confusion Matrix: TP={unet_metrics['TP']}, TN={unet_metrics['TN']}, FP={unet_metrics['FP']}, FN={unet_metrics['FN']}\")\n",
                "print(f\"Attention U-Net Confusion Matrix: TP={aunet_metrics['TP']}, TN={aunet_metrics['TN']}, FP={aunet_metrics['FP']}, FN={aunet_metrics['FN']}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "confusion_matrix"
            },
            "source": [
                "## 9. Confusion Matrix Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_cm"
            },
            "outputs": [],
            "source": [
                "# Plot confusion matrices\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# U-Net\n",
                "sns.heatmap(unet_cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=True)\n",
                "axes[0].set_title(f'U-Net Confusion Matrix\\n(AUC = {unet_metrics[\"AUC\"]:.4f})', \n",
                "                  fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('True Label', fontsize=12)\n",
                "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
                "axes[0].set_xticklabels(['Background', 'HRF'])\n",
                "axes[0].set_yticklabels(['Background', 'HRF'])\n",
                "\n",
                "# Attention U-Net\n",
                "sns.heatmap(aunet_cm, annot=True, fmt='d', cmap='Greens', ax=axes[1], cbar=True)\n",
                "axes[1].set_title(f'Attention U-Net Confusion Matrix\\n(AUC = {aunet_metrics[\"AUC\"]:.4f})', \n",
                "                  fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('True Label', fontsize=12)\n",
                "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
                "axes[1].set_xticklabels(['Background', 'HRF'])\n",
                "axes[1].set_yticklabels(['Background', 'HRF'])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrices.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "roc_curve"
            },
            "source": [
                "## 10. ROC Curve"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_roc"
            },
            "outputs": [],
            "source": [
                "# Calculate ROC curves\n",
                "y_true_flat = np.concatenate([y.flatten() for y in ground_truth])\n",
                "unet_pred_flat = np.concatenate([y.flatten() for y in unet_predictions])\n",
                "aunet_pred_flat = np.concatenate([y.flatten() for y in aunet_predictions])\n",
                "\n",
                "unet_fpr, unet_tpr, _ = roc_curve(y_true_flat, unet_pred_flat)\n",
                "aunet_fpr, aunet_tpr, _ = roc_curve(y_true_flat, aunet_pred_flat)\n",
                "\n",
                "unet_auc = auc(unet_fpr, unet_tpr)\n",
                "aunet_auc = auc(aunet_fpr, aunet_tpr)\n",
                "\n",
                "# Plot ROC curves\n",
                "plt.figure(figsize=(12, 8))\n",
                "plt.plot(unet_fpr, unet_tpr, color='blue', lw=2, \n",
                "         label=f'U-Net (AUC = {unet_auc:.4f})')\n",
                "plt.plot(aunet_fpr, aunet_tpr, color='green', lw=2, \n",
                "         label=f'Attention U-Net (AUC = {aunet_auc:.4f})')\n",
                "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random')\n",
                "\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate', fontsize=14)\n",
                "plt.ylabel('True Positive Rate', fontsize=14)\n",
                "plt.title('ROC Curves - HRF Segmentation', fontsize=16, fontweight='bold')\n",
                "plt.legend(loc=\"lower right\", fontsize=12)\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'roc_curves.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "metrics_comparison"
            },
            "source": [
                "## 11. Metrics Comparison Bar Plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_metrics"
            },
            "outputs": [],
            "source": [
                "# Metrics comparison\n",
                "metrics_to_plot = ['Dice', 'IoU', 'Precision', 'Recall', 'F1', 'Specificity', 'AUC']\n",
                "unet_values = [unet_metrics[m] for m in metrics_to_plot]\n",
                "aunet_values = [aunet_metrics[m] for m in metrics_to_plot]\n",
                "\n",
                "x = np.arange(len(metrics_to_plot))\n",
                "width = 0.35\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(14, 6))\n",
                "bars1 = ax.bar(x - width/2, unet_values, width, label='U-Net', color='steelblue', edgecolor='black')\n",
                "bars2 = ax.bar(x + width/2, aunet_values, width, label='Attention U-Net', color='mediumseagreen', edgecolor='black')\n",
                "\n",
                "# Add value labels\n",
                "for bars in [bars1, bars2]:\n",
                "    for bar in bars:\n",
                "        height = bar.get_height()\n",
                "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
                "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
                "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
                "ax.set_title('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels(metrics_to_plot)\n",
                "ax.set_ylim([0, 1.1])\n",
                "ax.legend(fontsize=12)\n",
                "ax.grid(True, axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'metrics_comparison.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "visualizations"
            },
            "source": [
                "## 12. Prediction Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "plot_predictions"
            },
            "outputs": [],
            "source": [
                "# Visualize predictions on sample images\n",
                "num_samples = min(5, len(test_images))\n",
                "fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4*num_samples))\n",
                "\n",
                "for i in range(num_samples):\n",
                "    # Original image\n",
                "    axes[i, 0].imshow(test_images[i])\n",
                "    axes[i, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
                "    axes[i, 0].axis('off')\n",
                "    \n",
                "    # Ground truth\n",
                "    axes[i, 1].imshow(ground_truth[i], cmap='gray')\n",
                "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
                "    axes[i, 1].axis('off')\n",
                "    \n",
                "    # U-Net prediction\n",
                "    axes[i, 2].imshow(unet_predictions[i], cmap='jet', vmin=0, vmax=1)\n",
                "    axes[i, 2].set_title('U-Net Prediction', fontsize=12, fontweight='bold')\n",
                "    axes[i, 2].axis('off')\n",
                "    \n",
                "    # Attention U-Net prediction\n",
                "    axes[i, 3].imshow(aunet_predictions[i], cmap='jet', vmin=0, vmax=1)\n",
                "    axes[i, 3].set_title('Attention U-Net Prediction', fontsize=12, fontweight='bold')\n",
                "    axes[i, 3].axis('off')\n",
                "    \n",
                "    # Overlay (U-Net)\n",
                "    overlay = test_images[i].copy()\n",
                "    mask_binary = (unet_predictions[i] > 0.5).astype(np.uint8)\n",
                "    overlay[mask_binary > 0, 0] = np.minimum(overlay[mask_binary > 0, 0] + 100, 255)\n",
                "    axes[i, 4].imshow(overlay)\n",
                "    axes[i, 4].set_title('U-Net Overlay', fontsize=12, fontweight='bold')\n",
                "    axes[i, 4].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(OUTPUT_DIR, 'predictions_visualization.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "summary"
            },
            "source": [
                "## 13. Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "summary_report"
            },
            "outputs": [],
            "source": [
                "# Generate and save summary report\n",
                "summary = f\"\"\"\n",
                "{'='*80}\n",
                "HRF SEGMENTATION U-NET EVALUATION SUMMARY\n",
                "{'='*80}\n",
                "\n",
                "Dataset: {len(test_image_paths)} test images\n",
                "Models: U-Net and Attention U-Net\n",
                "\n",
                "U-NET METRICS:\n",
                "{'-'*80}\n",
                "Dice Coefficient:  {unet_metrics['Dice']:.4f}\n",
                "IoU (Jaccard):     {unet_metrics['IoU']:.4f}\n",
                "Precision:         {unet_metrics['Precision']:.4f}\n",
                "Recall:            {unet_metrics['Recall']:.4f}\n",
                "F1-Score:          {unet_metrics['F1']:.4f}\n",
                "Specificity:       {unet_metrics['Specificity']:.4f}\n",
                "AUC:               {unet_metrics['AUC']:.4f}\n",
                "\n",
                "Confusion Matrix:\n",
                "  True Positives:  {unet_metrics['TP']:,}\n",
                "  True Negatives:  {unet_metrics['TN']:,}\n",
                "  False Positives: {unet_metrics['FP']:,}\n",
                "  False Negatives: {unet_metrics['FN']:,}\n",
                "\n",
                "ATTENTION U-NET METRICS:\n",
                "{'-'*80}\n",
                "Dice Coefficient:  {aunet_metrics['Dice']:.4f}\n",
                "IoU (Jaccard):     {aunet_metrics['IoU']:.4f}\n",
                "Precision:         {aunet_metrics['Precision']:.4f}\n",
                "Recall:            {aunet_metrics['Recall']:.4f}\n",
                "F1-Score:          {aunet_metrics['F1']:.4f}\n",
                "Specificity:       {aunet_metrics['Specificity']:.4f}\n",
                "AUC:               {aunet_metrics['AUC']:.4f}\n",
                "\n",
                "Confusion Matrix:\n",
                "  True Positives:  {aunet_metrics['TP']:,}\n",
                "  True Negatives:  {aunet_metrics['TN']:,}\n",
                "  False Positives: {aunet_metrics['FP']:,}\n",
                "  False Negatives: {aunet_metrics['FN']:,}\n",
                "\n",
                "{'='*80}\n",
                "Generated Files:\n",
                "  - confusion_matrices.png\n",
                "  - roc_curves.png\n",
                "  - metrics_comparison.png\n",
                "  - predictions_visualization.png\n",
                "  - evaluation_summary.txt\n",
                "{'='*80}\n",
                "\"\"\"\n",
                "\n",
                "print(summary)\n",
                "\n",
                "# Save to file\n",
                "with open(os.path.join(OUTPUT_DIR, 'evaluation_summary.txt'), 'w') as f:\n",
                "    f.write(summary)\n",
                "\n",
                "print(f\"\\nAll results saved to: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download"
            },
            "source": [
                "## 14. Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_results"
            },
            "outputs": [],
            "source": [
                "# Zip results for download\n",
                "import shutil\n",
                "from google.colab import files\n",
                "\n",
                "zip_path = '/content/hrf_evaluation_results'\n",
                "shutil.make_archive(zip_path, 'zip', OUTPUT_DIR)\n",
                "print(f\"Results packaged as: {zip_path}.zip\")\n",
                "\n",
                "# Download\n",
                "files.download(f'{zip_path}.zip')\n",
                "print(\"Download started!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}